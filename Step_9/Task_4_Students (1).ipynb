{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLYpSPDlW9LC"
      },
      "source": [
        "## Скачиваем необходимое\n",
        "\n",
        "Сначала нужно средствами NLTK загрузить WordNet.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhTQ6EFXZ5R9",
        "outputId": "0e6083ab-045a-4689-aa2e-d7749597fa5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIQ4rEytvwLZ"
      },
      "source": [
        "## Готовим данные к работе\n",
        "\n",
        "Затем импортируем данные из подготовленного текстового файла. Файл содержит набор пар слов (только имён существительных), для которых известны экспертные оценки сходства.\n",
        "\n",
        "Строим ассоциативный массив \"пара слов -- оценка близости\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_sTFACx3dAk8"
      },
      "outputs": [],
      "source": [
        "with open(\"wordsim_similarity_goldstandard.txt\", encoding=\"utf-8\") as rf:\n",
        "  triples = [line.strip().split(\"\\t\") for line in rf.readlines()]\n",
        "  score_map = {tuple(triple[:2]): float(triple[2]) for triple in triples}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_map"
      ],
      "metadata": {
        "id": "_yLojXDOITGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "triples = []\n",
        "score_map = {}\n",
        "with open('Task_4_sample_4.csv', 'r') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    next(reader, None)  # skip the header\n",
        "    for row in reader:\n",
        "        pair = (row[0], row[1])\n",
        "        score = float(row[2])\n",
        "        triples.append(pair)\n",
        "        score_map[pair] = score"
      ],
      "metadata": {
        "id": "HAPwOtAeEky3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_map"
      ],
      "metadata": {
        "id": "5sczX4QfIRDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD8NC87BBFej"
      },
      "source": [
        "Отметим, что из исходного набора данных мы взяли только экспертные оценки сходства (similarity) и только для существительных. Исходный набор данных доступен по [ссылке](http://alfonseca.org/pubs/ws353simrel.tar.gz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96B0OtKrvtaG"
      },
      "source": [
        "Посмотрим на примеры оценок. \n",
        "\n",
        "У слов может быть по несколько значений, которые различаются в WordNet. Здесь -- ради примера -- мы будем \"жадно\" выбирать первое попавшееся, но далее будем работать с ними иначе.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iXamIiZgf-O",
        "outputId": "35781b52-4b30-4a00-aee2-31169bcbfc26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Words: professor-cucumber\n",
            "Ground truth score: 0.31\n",
            "\n",
            "Path: 0.077 \n",
            "wup: 0.500 \n",
            "shortest_path: 12.000\n",
            "\n",
            "Words: monk-slave\n",
            "Ground truth score: 0.92\n",
            "\n",
            "Path: 0.200 \n",
            "wup: 0.667 \n",
            "shortest_path: 4.000\n"
          ]
        }
      ],
      "source": [
        "for w1, w2 in list(score_map)[:2]:\n",
        "  \n",
        "  print(\"\\nWords: %s-%s\\nGround truth score: %.2f\" % (w1, w2, score_map[(w1, w2)]))\n",
        "  \n",
        "  ss1 = wn.synset(w1 + \".n.01\")\n",
        "  ss2 = wn.synset(w2 + \".n.01\")\n",
        "\n",
        "  print(\"\\nPath: %.3f\" % ss1.path_similarity(ss2), end=\" \")\n",
        "  print(\"\\nwup: %.3f\" % ss1.wup_similarity(ss2), end=\" \")\n",
        "  print(\"\\nshortest_path: %.3f\" % ss1.shortest_path_distance(ss2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHM7tCb0vqNp"
      },
      "source": [
        "Вычисляем для всех пар несколько оценок"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "fe7Nuglqgnd3"
      },
      "outputs": [],
      "source": [
        "from itertools import product\n",
        "\n",
        "list_pairs = list(score_map)\n",
        "wup_list, true_list, path_list = [], [], []\n",
        "\n",
        "# для всех пар\n",
        "for w1, w2 in list_pairs:\n",
        "\n",
        "  try:\n",
        "    all_w1 = wn.synsets(w1, pos=\"n\")\n",
        "    all_w2 = wn.synsets(w2, pos=\"n\")\n",
        "\n",
        "    # добавляем интересующие нас метрики и экспертные оценки\n",
        "    wup = max([item1.wup_similarity(item2) \\\n",
        "                for item1, item2 in product(all_w1, all_w2)])\n",
        "    wup_list.append(wup)\n",
        "\n",
        "    path = max([item1.path_similarity(item2) \\\n",
        "                for item1, item2 in product(all_w1, all_w2)])\n",
        "    path_list.append(path)\n",
        "    \n",
        "    true_list.append(score_map[(w1, w2)])\n",
        "\n",
        "  except Exception as e:\n",
        "    print(w1, w2, \"error:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAjuTLB0fD-I"
      },
      "source": [
        "## Вычисляем ранговую корреляцию Спирмена"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXnCdw8wxcVd",
        "outputId": "dfecdf40-2957-4e3d-8396-ece99d720f8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wup  Spearman R: 0.6936\n",
            "path Spearman R: 0.6535\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import spearmanr\n",
        "\n",
        "coef, p = spearmanr(wup_list, true_list)\n",
        "print(\"wup  Spearman R: %.4f\" % coef)\n",
        "\n",
        "coef, p = spearmanr(path_list, true_list)\n",
        "print(\"path Spearman R: %.4f\" % coef)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate similarity scores and true scores for each pair\n",
        "wup_list, true_list, path_list, lch_list = [], [], [], []\n",
        "for w1, w2 in triples:\n",
        "    try:\n",
        "        all_w1 = wn.synsets(w1, pos='n')\n",
        "        all_w2 = wn.synsets(w2, pos='n')\n",
        "\n",
        "        # Compute similarity scores\n",
        "        wup = max([item1.wup_similarity(item2) for item1, item2 in product(all_w1, all_w2)])\n",
        "        wup_list.append(wup)\n",
        "\n",
        "        path = max([item1.path_similarity(item2) for item1, item2 in product(all_w1, all_w2)])\n",
        "        path_list.append(path)\n",
        "\n",
        "        lch = max([item1.lch_similarity(item2) for item1, item2 in product(all_w1, all_w2)])\n",
        "        lch_list.append(lch)\n",
        "\n",
        "        # Add true scores\n",
        "        true_list.append(score_map[(w1, w2)])\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "# Compute Spearman correlation coefficients for each similarity measure\n",
        "wup_coef, _ = spearmanr(wup_list, true_list)\n",
        "path_coef, _ = spearmanr(path_list, true_list)\n",
        "lch_coef, _ = spearmanr(lch_list, true_list)\n",
        "\n",
        "# Print the results\n",
        "print('Spearman R for wup_similarity: {:.4f}'.format(wup_coef))\n",
        "print('Spearman R for path_similarity: {:.4f}'.format(path_coef))\n",
        "print('Spearman R for lch_similarity: {:.4f}'.format(lch_coef))\n",
        "\n",
        "# Find the number of hyponyms for the synset \"wood.n.01\" and the name of the first hyponym\n",
        "wood_synset = wn.synset('wood.n.01')\n",
        "hyponyms = wood_synset.hyponyms()\n",
        "num_hyponyms = len(hyponyms)\n",
        "first_hyponym_name = hyponyms[0].name()\n",
        "\n",
        "print('Number of hyponyms for wood.n.01:', num_hyponyms)\n",
        "print('Name of the first hyponym:', first_hyponym_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U9OpKoFJA7O",
        "outputId": "54c17ede-f828-4a9e-af86-7a0a7a97413c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spearman R for wup_similarity: 0.6936\n",
            "Spearman R for path_similarity: 0.6535\n",
            "Spearman R for lch_similarity: 0.6535\n",
            "Number of hyponyms for wood.n.01: 91\n",
            "Name of the first hyponym: alder.n.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "wup  Spearman R: 0.6438\n",
        "path Spearman R: 0.6176"
      ],
      "metadata": {
        "id": "W9UUpylzCz1F"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}